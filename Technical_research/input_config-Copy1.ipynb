{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf000cc",
   "metadata": {},
   "source": [
    "#### Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdbc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import itertools\n",
    "from print_color import print\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cdc8f",
   "metadata": {},
   "source": [
    "# 3D to 2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d64f879",
   "metadata": {},
   "source": [
    "#### MIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac43c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mip(image: np.ndarray)->np.ndarray:\n",
    "    \"\"\"Create the maximum intensity projection.\n",
    "    \"\"\"\n",
    "    maximum_intensity_projection = np.max(image, axis=0)\n",
    "    maximum_intensity_projection = np.clip(maximum_intensity_projection, -100, 300)\n",
    "    \n",
    "    return maximum_intensity_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad429d77",
   "metadata": {},
   "source": [
    "#### AIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8637d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aip(image: np.ndarray)->np.ndarray:\n",
    "    \"\"\"Create a mean image projection.\n",
    "    \"\"\"\n",
    "    average_intensity_projection = np.mean(image,axis=0)\n",
    "    average_intensity_projection = np.clip(average_intensity_projection,-100,300)\n",
    "    \n",
    "    return average_intensity_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47940261",
   "metadata": {},
   "source": [
    "#### SLICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c8f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tumor_center(mask: np.ndarray)->int:\n",
    "    \"\"\"Find the center of the tumor. \n",
    "    \"\"\"\n",
    "    return np.clip(np.argmax(np.sum(mask, axis=(1, 2))),-100,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf90413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_tc(image: np.ndarray, mask: np.ndarray)->np.ndarray:\n",
    "    \"\"\"Take a slice at the center of the tumor.\n",
    "    \"\"\"\n",
    "    x1 = find_tumor_center(mask)\n",
    "    return np.clip(image[x1, :, :],-100,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e21f5",
   "metadata": {},
   "source": [
    "#### TUMOR MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3be8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_mip(image: np.ndarray, mask: np.ndarray)->np.ndarray:\n",
    "    \"\"\"Return the mip of the tumor only.\n",
    "    \"\"\"\n",
    "    return np.clip(np.max(image * mask, axis=0),-100,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273bfb2",
   "metadata": {},
   "source": [
    "#### MINIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2152a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minip(image: np.ndarray)->np.ndarray:\n",
    "    \"\"\"Create the maximum intensity projection.\n",
    "    \"\"\"\n",
    "    return np.clip(np.min(image, axis=0),-100,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75521333",
   "metadata": {},
   "source": [
    "# Convert the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5607fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MIP = []\n",
    "AIP = []\n",
    "SLICE = []\n",
    "TUMOR_MIP = []\n",
    "MINIP = []\n",
    "\n",
    "with open('c:/users/sven/Documents/BEP_sbierenbroodspot_1334859/Pyradiomics/v5/folderNames2.csv', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        img_data = sitk.GetArrayFromImage(sitk.ReadImage(row[1]))\n",
    "\n",
    "        if os.path.exists(row[2]):\n",
    "            mask_data = sitk.GetArrayFromImage(sitk.ReadImage(row[2]))\n",
    "        else:\n",
    "            mask_l = sitk.GetArrayFromImage(sitk.ReadImage(row[3]))\n",
    "            mask_r = sitk.GetArrayFromImage(sitk.ReadImage(row[4]))\n",
    "            mask_data = mask_l+mask_r\n",
    "\n",
    "        MIP.append(mip(img_data))\n",
    "        AIP.append(aip(img_data))\n",
    "        SLICE.append(slice_tc(img_data,mask_data))\n",
    "        TUMOR_MIP.append(tumor_mip(img_data,mask_data))\n",
    "        MINIP.append(minip(img_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69456d",
   "metadata": {},
   "source": [
    "# feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2375615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IAC(layout: list, i: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create the 512x512x3 input array for feature extraction.\n",
    "    \"\"\"\n",
    "    slots = [MIP[i], AIP[i], SLICE[i], TUMOR_MIP[i], MINIP[i]]\n",
    "    input_array = np.dstack([slots[layout[j] - 1] for j in range(3)])\n",
    "    return input_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29346ebb",
   "metadata": {},
   "source": [
    "#### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdfd95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['resnest50d', 'efficientnet_b4', 'gluon_resnet152_v1s','convnext_nano','convnext_large','resnetv2_101','efficientnetv2_rw_m']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89cac1",
   "metadata": {},
   "source": [
    "#### Feature extraction single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b79e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(input_array: np.ndarray)-> np.ndarray:\n",
    "    \"\"\"Extract the features of a single image.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Convert numpy array to torch tensor and normalize\n",
    "    input_tensor = torch.from_numpy(np.transpose(input_array, (2, 0, 1))).float()\n",
    "    input_tensor = input_tensor.to('cuda')\n",
    "    input_tensor = (input_tensor + 100) / (300 + 100)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Extract features using ResNet50\n",
    "    with torch.no_grad():\n",
    "        features = model.forward_features(input_tensor)\n",
    "        features = torch.mean(features, dim=[2, 3])\n",
    "\n",
    "    # Convert features to numpy array\n",
    "    features = features.to('cpu')\n",
    "    features_array = features.numpy()\n",
    "    \n",
    "    return features_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed223716",
   "metadata": {},
   "source": [
    "#### Feature extraction full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b3f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_full(layout: list, sizing) -> np.ndarray:\n",
    "    \"\"\"Extract all features of the dataset for an input layout.\n",
    "    \"\"\"\n",
    "    sizes = [2048, 1792, 2048, 640, 1536, 2048, 2152]\n",
    "    result = np.empty((0, sizes[sizing]))\n",
    "\n",
    "    for i in range(len(MIP)):\n",
    "        result_vector = feature_extraction(IAC(layout, i))\n",
    "        result = np.vstack([result, result_vector])    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54b189",
   "metadata": {},
   "source": [
    "#### Extract manual result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63cc52ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 32, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result  \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(svm_auc(result, labels))\n",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m, in \u001b[0;36mfeature_extraction_full\u001b[1;34m(layout, sizing)\u001b[0m\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, sizes[sizing]))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(MIP)):\n\u001b[1;32m----> 8\u001b[0m     result_vector \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIAC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([result, result_vector])    \n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[1;34m(input_array)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract features using ResNet50\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 13\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(features, dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert features to numpy array\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\resnet.py:717\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4], x, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    719\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\resnest.py:119\u001b[0m, in \u001b[0;36mResNestBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavd_first \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavd_first(out)\n\u001b[1;32m--> 119\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m    121\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_block(out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\timm\\models\\layers\\split_attn.py:75\u001b[0m, in \u001b[0;36mSplitAttn.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m x_gap \u001b[38;5;241m=\u001b[39m x_gap\u001b[38;5;241m.\u001b[39mmean((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m x_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x_gap)\n\u001b[1;32m---> 75\u001b[0m x_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_gap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m x_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact1(x_gap)\n\u001b[0;32m     77\u001b[0m x_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x_gap)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2448\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2436\u001b[0m         batch_norm,\n\u001b[0;32m   2437\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2445\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2446\u001b[0m     )\n\u001b[0;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m-> 2448\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2416\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2414\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(size))\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 32, 1, 1])"
     ]
    }
   ],
   "source": [
    "result  = feature_extraction_full([3, 3, 3], 0)\n",
    "print(svm_auc(result, labels))\n",
    "#np.savetxt(\"result.csv\", result, delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e7c59",
   "metadata": {},
   "source": [
    "# Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49c9994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.empty((0,0))\n",
    "with open('c:/users/sven/Documents/BEP_sbierenbroodspot_1334859/Technical_research/Labels.csv', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels = np.append(labels, row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807d5a3",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4779e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_auc(data: np.ndarray, labels: np.ndarray)->np.float64:\n",
    "    \"\"\"Get the AUC for a svm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a stratified 5-fold cross-validation object\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "    # Initialize an SVM classifier\n",
    "    svm = SVC(kernel='linear', probability=True, random_state = 2)\n",
    "\n",
    "    # Store the AUC scores\n",
    "    auc_scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, test_idx in cv.split(data, labels):\n",
    "        # Split the data and labels\n",
    "        X_train, X_test = data[train_idx], data[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        # Train the SVM classifier\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        #Predict the probabilities for the test set\n",
    "        \n",
    "        y_pred_proba = svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute the AUC score\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        # Store the AUC score\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    return np.mean(auc_scores), np.std(auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83352f7",
   "metadata": {},
   "source": [
    "# Get all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "076c4f33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7442424242424244\u001b[0m\n",
      "0.8181818181818181\u001b[0m\n",
      "0.8270707070707071\u001b[0m\n",
      "0.8377777777777778\u001b[0m\n",
      "0.7282828282828282\u001b[0m\n",
      "0.7222222222222222\u001b[0m\n",
      "0.7836363636363636\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "auc_total = []\n",
    "stds_total = []\n",
    "\n",
    "\n",
    "for n in range(7):\n",
    "\n",
    "    model = timm.create_model(models[n], pretrained=True)\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "    auc = []\n",
    "    stds = []\n",
    "    \n",
    "    for i in [1,2,4,5]:\n",
    "        for j in [1,2,4,5]:\n",
    "            for k in [1,2,4,5]:\n",
    "\n",
    "                my_list = [i, j, k]\n",
    "                auc_ = svm_auc(feature_extraction_full(my_list, n),labels)\n",
    "                auc.append(auc_[0])\n",
    "                stds.append(auc_[1])\n",
    "    \n",
    "    print(np.max(auc))\n",
    "    auc_total.append(auc)\n",
    "    stds_total.append(stds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74385fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"aucs.csv\", np.transpose(auc_total), delimiter=\",\") \n",
    "np.savetxt(\"stds.csv\", np.transpose(stds_total), delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bdf319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49676767676767686\u001b[0m\n",
      "0.0788432853613209\u001b[0m\n",
      "0.5\u001b[0m\n",
      "0.15777376836303011\u001b[0m\n",
      "0.4675757575757576\u001b[0m\n",
      "0.1484031933798124\u001b[0m\n",
      "0.608989898989899\u001b[0m\n",
      "0.07891623835597793\u001b[0m\n",
      "0.48434343434343424\u001b[0m\n",
      "0.11987052158349658\u001b[0m\n",
      "0.5898989898989898\u001b[0m\n",
      "0.07580268017559731\u001b[0m\n",
      "0.44727272727272727\u001b[0m\n",
      "0.0847748598318165\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "auc_total = []\n",
    "stds_total = []\n",
    "\n",
    "\n",
    "for n in range(7):\n",
    "\n",
    "    model = timm.create_model(models[n], pretrained=True)\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "    auc = []\n",
    "    stds = []\n",
    "    \n",
    "    auc_ = svm_auc(feature_extraction_full([3,3,3], n),labels)\n",
    "    auc.append(auc_[0])\n",
    "    stds.append(auc_[1])\n",
    "    \n",
    "    print(np.max(auc))\n",
    "    print(np.max(stds))\n",
    "    auc_total.append(auc)\n",
    "    stds_total.append(stds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcd788",
   "metadata": {},
   "source": [
    "# String generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_file.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for i in range(1, 6):\n",
    "        for j in range(1, 6):\n",
    "            for k in range(1, 6):\n",
    "               \n",
    "                my_list = [i, j, k]\n",
    "                    \n",
    "                csvwriter.writerow([str(my_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309df7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
